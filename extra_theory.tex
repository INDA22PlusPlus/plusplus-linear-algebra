\documentclass{report}

\include{preamble}
\include{macros}
\include{letterfonts}

\title{\Huge{SF1624 Linjär algebra och geometri, bra formler}}
\author{\huge{}}
\date{}


\begin{document}

\maketitle
\newpage
\pdfbookmark[section]{\contentsname}{toc}
\tableofcontents
\pagebreak

\chapter{}

\thm{Matrisen som projekterar på $ \vec{v}  $ }
{
	För att slippa hålla på med beräkningar med bråktal för att hitta matrisen som beskriver projektionen på vektorn $ \vec{v}  $, så kan man använda formeln nedan:
\[
A = \frac{1}{\vec{v} \cdot \vec{v} } \vec{v} \vec{v}^T
\]
Därmed projektionen av vektorn $ \vec{x} $ på vektorn $ \vec{v}  $ beskrivs av matrismultiplikationen $ proj_{ \vec{v} } \vec{x} = A \vec{x}  $  
}

\thm{Matrisen som projekterar på vektorrummet $ V $ }
{
Om vektorummet definieras som $ V := col(A) $, då beskrivs matrisen som projekterar på vektorrummet $ V $ på följande sättet:
\[
	P = A (A^T A)^{-1} A^T
\]
Alltså för att projektera givna vektorn $ \vec{x}  $ på vektorummet $ V $, så använder man följande matrismultiplikation $ P \vec{x}  $. \textbf{Notera} att det är exakt samma metod som används för minstakvadratmetoden. Projektionen av en vektor på en vektorummet ger den bästa approximationen av givna vektorn på vektorrummet. 
}

\thm{Ortogonala komplementet till delrummet $ V \in \mathbb{R}^n $ }
{
Om man vill hitta ortogonala komplementet (också delrum) till delrummet $ V $ med villkorn att $ V $ inte spannar hela $ \mathbb{R}^n $, så använder man formeln nedan. \textbf{Observera} att $ V := col(A) $
\[
	V^\perp = ker(A^T) = null(A^T)
\]
	\textbf{Varför}: En ortogonal komplement $ V^\perp $ till delrummet $ V $ innebär att $ \forall \vec{v} \in V^\perp,\: \forall \vec{u} \in V \implies  v \cdot u = 0$. Om $ A $ beskrivs som $ 
\begin{bmatrix}
	w_1 & \ldots  & w_k \\
\end{bmatrix}
$ så kommer $ A^T $ beskrivas på sättet nedan.

\[ A^T =
\begin{bmatrix}
	w_1 \\
	\vdots \\
	w_k \\
\end{bmatrix}
\]
Om man multiplicerar $ A^T $ med en vektor $ \vec{x}  $ och försöker bestämma noll-rummet så bestämmer vi per definition ortogonala komponentet. D.v.s rummet där varje vektor $ \vec{x} \in \mathbb{R}^n $ ger 0 med skalärprodukten av varje vektor som spannar V ($ w_1, \ldots w_k $), som det kan ses nedan.

\[
null(A^T) = ker(A^T) :=
\begin{bmatrix}
	w_1 \cdot \vec{x}  \\
	\vdots \\
	w_k \cdot \vec{x} \\
\end{bmatrix} =
\begin{bmatrix}
	0 \\
	\vdots \\
	0 \\
\end{bmatrix}
\]

}

\thm{En vektor $ \vec{x}  $ kan skrivas som projektionen på en vektorrum + projektionens ortogonala komplement}
{
För att kunna bevisa 1.0.2 så brukar man använda denna sats som beskrivs nedan.
\[
	\vec{x} = proj_W \vec{x} + proj_{W^\perp} \vec{x}  
\]
\[
		proj_{W^\perp} \vec{x} = \vec{x} - proj_W \vec{x} 
\]


}

\thm{Hitta resterande basvektorer i $ \mathbb{R}^n $ utifrån en mängd linjärt oberoende vektorer $ S $}
{
För det, måste storleken av $ S $ vara mindre än $ n $, annars är $ S $ redan en bas för $ \mathbb{R}^n $. Om $ S = \{ w_1, \cdots, w_k\} $, så sätter vi upp dessa vektorer som kolumnelement och sedan löser noll-rummet, som det kan ses nedan.
\[
A =
\begin{bmatrix}
	w_1 \\
	\vdots \\
	w_k
\end{bmatrix}; \: B := null(A) = ker(A)
\]
\textbf{Varför}: Som i 1.0.3 så försöker vi hitta en mängd vektorer ($ B $) som är ortogonala och därmed linjärt oberoende mot varje vektor i $ S $. Detta är ekvivalent med att varje vektor i mängden vektorer vi försöker lösa, $ B $, har skalärprodukten 0 med varje vektor i $ S $. Enligt kraven för linjärt oberoendet av basvektorerna så blir mängden $ S \cup B $ en bas för $ \mathbb{R}^n $.  
}

\end{document}
